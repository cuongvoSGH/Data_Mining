{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bb9781",
   "metadata": {},
   "source": [
    "## Churn detection - Classification Problem\n",
    "\n",
    "In this use case, we look at how a mobile phone carrier company can proactively identify customers more likely to churn in the near term in order to improve the service and create custom outreach campaigns that help retain the customers.\n",
    "\n",
    "Mobile phone carriers face an extremely competitive market. Many mobile carriers lose revenue from postpaid customers due to churn. Hence the ability to proactively and accurately identify customer churn at scale can be a huge competitive advantage. Some of the factors contributing to mobile phone customer churn includes: Perceived frequent service disruptions, poor customer service experiences in online/retail stores, offers from other competing carriers (better family plan, data plan, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47584a3c",
   "metadata": {},
   "source": [
    "## 1. Understand data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7ec5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"g:/My Drive/diamonds_preproc.py\"\n",
    "import numpy as np        \n",
    "import pandas as pd       \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "df = pd.read_csv(\"churn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e882a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9550d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6551f519",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb684c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa465e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a2eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449f7212",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1686b8",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b45b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e72e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b11c5e",
   "metadata": {},
   "source": [
    "### cutoff treshold for score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996c2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363d416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe990a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e152b148",
   "metadata": {},
   "source": [
    "### Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324992f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bca1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d05b1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cafd4778",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cab39",
   "metadata": {},
   "source": [
    "\n",
    "* accuracy: ratio of correct predictions to the total number of samples in dataset - in the case of imbalanced classes this metric can be misguiding \n",
    "\n",
    "* true positive (TP)— sample’s label is positive and it is classified as one\n",
    "* true negative (TN) — sample’s label is negative and it is classified as one\n",
    "* false positive (FP)— sample’s label is neg., but it is classified as positive\n",
    "* false negative (FN)— sample’s label is pos., but it classified as negative\n",
    "\n",
    "![](graphs/metrics.jpg)\n",
    "\n",
    "\n",
    "#### 1. True Positive Rate (also sensitivity or recall)\n",
    "Recall metric shows how many relevant samples are selected, which means how well our model can predict all the interested samples in our dataset.\n",
    "\n",
    "#### 2. Precision\n",
    "Precision metric tells us how many predicted samples are relevant i.e. our mistakes into classifying sample as a correct one if it’s not true.\n",
    "$$\\frac{TP}{TP+FP} $$\n",
    "\n",
    "#### 3. Recall (TPR or sensitivity)\n",
    "Recall metric shows how many relevant samples are selected, which means how well our model can predict all the interested samples in our dataset.\n",
    "Recall is the percentage of actual positives that were correctly classified \n",
    "$$\\frac{TP}{TP+FN} $$\n",
    "\n",
    "#### 4. FPR \n",
    "$$\\frac{FP}{FP+TN} $$\n",
    "\n",
    "\n",
    "#### 5. ROC \n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "* True Positive Rate\n",
    "* False Positive Rate\n",
    "ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.\n",
    "![](graphs/roc.svg)\n",
    "\n",
    "\n",
    "#### 6. AUC \n",
    "AUC refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than a random negative sample. \n",
    "![](graphs/auc.svg)\n",
    "AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.\n",
    "\n",
    "AUC is desirable for the following two reasons:\n",
    "* AUC is scale-invariant. It measures how well predictions are ranked, rather than their absolute values.\n",
    "* AUC is classification-threshold-invariant. It measures the quality of the model's predictions irrespective of what classification threshold is chosen.\n",
    "\n",
    "\n",
    "#### 7. AUPRC \n",
    "AUPRC refers to Area Under the Curve of the Precision-Recall Curve. This metric computes precision-recall pairs for different probability thresholds. \n",
    "A precision-recall curve (or PR Curve) is a plot of the precision (y-axis) and the recall (x-axis) for different probability thresholds.\n",
    "* PR Curve: Plot of Recall (x) vs Precision (y).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 4. F1-score\n",
    "F1 metric is the harmonic average of the precision and recall. This metric is a good choice for the imbalanced classification scenario. The range of F1 is in [0, 1], where 1 is perfect classification and 0 is total failure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ef661",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
